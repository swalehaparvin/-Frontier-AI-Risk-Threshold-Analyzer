{
  "frameworks": [
    {
      "organization": "OpenAI",
      "framework_name": "Preparedness Framework",
      "version": "Beta",
      "risk_tiers": [
        {
          "tier_name": "Cybersecurity",
          "tier_level": 1,
          "capability_threshold": "Model assistance for cyber attacks is meaningful only for non-programming uses, e.g., translation, targeted distillation of confidential information, and/or data analysis AND model cannot meaningfully execute elements of cyber operations.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Cyber theory of attack eval: On a dataset of challenging conceptual multiple-choice questions extracted and rephrased from pentest writeups, the model performs significantly below the human baseline.",
            "GPT vs search availability exploit eval: On a set of misconfigured web servers vulnerable to denial of service, cybersecurity professionals find <X% more bugs when provided with GPT assistance."
          ],
          "required_safeguards": [
            "Implementing security measures to prevent model exfiltration."
          ],
          "deployment_restrictions": [
            "Only models with a post-mitigation score of 'medium' or below can be deployed."
          ],
          "source_quote": "Model assistance for cyber attacks is meaningful only for non-programming uses."
        },
        {
          "tier_name": "CBRN",
          "tier_level": 1,
          "capability_threshold": "Model can provide information relevant to creating CBRN threats with comparable utility to existing resources (e.g., textbooks, search engines).",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "GPT vs search eval: Post-PhD professionals trained in biology experience no improvement in success rates for writing CDC Class B biological agent development instructions using a search engine and GPT."
          ],
          "required_safeguards": [
            "Implementing security measures to prevent model exfiltration."
          ],
          "deployment_restrictions": [
            "Only models with a post-mitigation score of 'medium' or below can be deployed."
          ],
          "source_quote": "Model can provide information relevant to creating CBRN threats with comparable utility to existing resources."
        },
        {
          "tier_name": "Persuasion",
          "tier_level": 2,
          "capability_threshold": "Model can create (potentially interactive) content with comparable persuasive effectiveness to typical human-written content.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Political articles eval: Content generated by model increases rate of human belief in a political issue significantly compared to human-generated controls."
          ],
          "required_safeguards": [
            "Implementing security measures to prevent model exfiltration."
          ],
          "deployment_restrictions": [
            "Only models with a post-mitigation score of 'medium' or below can be deployed."
          ],
          "source_quote": "Model can create (potentially interactive) content with comparable persuasive effectiveness to typical human-written content."
        },
        {
          "tier_name": "Model Autonomy",
          "tier_level": 2,
          "capability_threshold": "Model can robustly complete a diverse set of chained actions and acquire resources.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Server purchase eval: With extensive scaffolding, the model can buy additional server space (>X% success rate)."
          ],
          "required_safeguards": [
            "Implementing security measures to prevent model exfiltration."
          ],
          "deployment_restrictions": [
            "Only models with a post-mitigation score of 'medium' or below can be deployed."
          ],
          "source_quote": "Model can robustly complete a diverse set of chained actions and acquire resources."
        }
      ]
    },
    {
      "organization": "Meta",
      "framework_name": "Frontier AI Framework",
      "version": "1.1",
      "risk_tiers": [
        {
          "tier_name": "Critical",
          "tier_level": 1,
          "capability_threshold": "The model would uniquely enable the execution of at least one of the threat scenarios that have been identified as potentially sufficient to produce a catastrophic outcome and that risk cannot be mitigated in the proposed deployment context.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Conduct a threat modeling exercise to determine whether other barriers to realizing the catastrophic outcome exist."
          ],
          "required_safeguards": [
            "Access is strictly limited to a small number of experts, alongside security protections to prevent hacking or exfiltration insofar as is technically feasible and commercially practicable."
          ],
          "deployment_restrictions": [
            "Stop development."
          ],
          "source_quote": "If a model appears to uniquely enable the execution of a threat scenario we will pause development while we investigate whether barriers to realizing the catastrophic outcome remain."
        },
        {
          "tier_name": "High",
          "tier_level": 2,
          "capability_threshold": "The model provides significant uplift towards execution of a threat scenario (i.e. significantly enhances performance on key capabilities or tasks needed to produce a catastrophic outcome) but does not enable execution of any threat scenario that has been identified as potentially sufficient to produce a catastrophic outcome.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Implement mitigations to reduce risk to moderate levels."
          ],
          "required_safeguards": [
            "Access is limited to a core research team, alongside security protections to prevent hacking or exfiltration."
          ],
          "deployment_restrictions": [
            "Do not release."
          ],
          "source_quote": "Successful execution of a threat scenario does not necessarily mean that the catastrophic outcome is realizable."
        },
        {
          "tier_name": "Moderate",
          "tier_level": 3,
          "capability_threshold": "The model would not provide significant uplift towards execution of a threat scenario.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Security measures will depend on the release strategy."
          ],
          "required_safeguards": [
            "Mitigations will depend on the results of evaluations and the release strategy."
          ],
          "deployment_restrictions": [],
          "source_quote": "At present, the science of evaluation is not sufficiently robust as to provide definitive quantitative metrics for uplift."
        }
      ]
    },
    {
      "organization": "Cohere",
      "framework_name": "Cohere Secure AI Frontier Model Framework",
      "version": "V1.0",
      "risk_tiers": [
        {
          "tier_name": "ASL-1",
          "tier_level": 1,
          "capability_threshold": "Basic AI capabilities with minimal risk of harmful outputs.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Basic performance evaluations",
            "Initial safety assessments"
          ],
          "required_safeguards": [
            "Basic security measures",
            "Access controls"
          ],
          "deployment_restrictions": [],
          "source_quote": "Cohere\u2019s models are being used now, at scale, to enable businesses of all sizes to enhance their offerings and better serve their customers."
        },
        {
          "tier_name": "ASL-2",
          "tier_level": 2,
          "capability_threshold": "Intermediate AI capabilities with moderate risk of harmful outputs.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Comprehensive performance evaluations",
            "Safety and security assessments"
          ],
          "required_safeguards": [
            "Enhanced security measures",
            "Regular audits"
          ],
          "deployment_restrictions": [
            "Limited to enterprise environments"
          ],
          "source_quote": "Enterprises are required to satisfy an ever-growing list of standards and requirements."
        },
        {
          "tier_name": "ASL-3",
          "tier_level": 3,
          "capability_threshold": "Advanced AI capabilities with high risk of harmful outputs.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Rigorous performance evaluations",
            "Third-party security testing"
          ],
          "required_safeguards": [
            "Comprehensive security protocols",
            "Continuous monitoring"
          ],
          "deployment_restrictions": [
            "Restricted to high-security environments"
          ],
          "source_quote": "Cohere prioritizes efforts to ensure that these safety and security needs are met."
        }
      ]
    },
    {
      "organization": "Microsoft",
      "framework_name": "Frontier Governance Framework",
      "version": "1 (February 2025)",
      "risk_tiers": [
        {
          "tier_name": "CBRN weapons",
          "tier_level": 1,
          "capability_threshold": "The model either does not respond to queries related to developing and delivering CBRN attacks or responds with information that is already publicly available.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Deployment allowed in line with Responsible AI Program requirements."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "Low: The model either does not respond to queries related to developing and delivering CBRN attacks or responds with information that is already publicly available."
        },
        {
          "tier_name": "CBRN weapons",
          "tier_level": 2,
          "capability_threshold": "The model provides some assistance increasing the ability of an existing expert (PhD level education in related fields) to develop a known CBRN threat.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Deployment allowed in line with Responsible AI Program requirements."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "Medium: The model provides some assistance increasing the ability of an existing expert (PhD level education in related fields) to develop a known CBRN threat."
        },
        {
          "tier_name": "CBRN weapons",
          "tier_level": 3,
          "capability_threshold": "The model provides a meaningful uplift to an expert\u2019s (PhD level education in related fields) ability to develop and deliver a novel CBRN threat. The model provides a meaningful uplift to a medium-skilled actor\u2019s (e.g., STEM education) ability to develop and deliver a known CBRN threat.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Further review and mitigations required."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "High: The model provides a meaningful uplift to an expert\u2019s ability to develop a highly dangerous novel threat or significantly lowers the barriers to a low-skilled actor developing and delivering a known CBRN threat."
        },
        {
          "tier_name": "CBRN weapons",
          "tier_level": 4,
          "capability_threshold": "The model provides a meaningful uplift to an expert\u2019s ability to develop a highly dangerous novel threat or significantly lowers the barriers to a low-skilled actor developing and delivering a known CBRN threat.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Further review and mitigations required."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "Critical: The model provides a meaningful uplift to an expert\u2019s ability to develop a highly dangerous novel threat or significantly lowers the barriers to a low-skilled actor developing and delivering a known CBRN threat."
        },
        {
          "tier_name": "Offensive cyberoperations",
          "tier_level": 1,
          "capability_threshold": "The model supports gathering of publicly available information related to cyber security threats, including through question and answer or content generation, but cannot meaningfully plan or execute a cyberattack.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Deployment allowed in line with Responsible AI Program requirements."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "Low: The model supports gathering of publicly available information related to cyber security threats, including through question and answer or content generation, but cannot meaningfully plan or execute a cyberattack."
        },
        {
          "tier_name": "Offensive cyberoperations",
          "tier_level": 2,
          "capability_threshold": "The model increases the ability of a low-skilled actor to conduct low-level spoofing, phishing, or social engineering attacks by partially automating discrete tasks related to vulnerability exploitation like generic target identification and planning (but not execution).",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Deployment allowed in line with Responsible AI Program requirements."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "Medium: The model increases the ability of a low-skilled actor to conduct low-level spoofing, phishing, or social engineering attacks by partially automating discrete tasks related to vulnerability exploitation like generic target identification and planning (but not execution)."
        },
        {
          "tier_name": "Offensive cyberoperations",
          "tier_level": 3,
          "capability_threshold": "The model provides meaningful uplift to a low-to-medium skilled actor\u2019s ability to create and conduct highly disruptive or destructive cyber-attacks, including on critical infrastructure, for example, through discovering novel zero-day exploit chains or developing complex malware or other tactics, techniques, and procedures.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Further review and mitigations required."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "High: The model provides meaningful uplift to a low-to-medium skilled actor\u2019s ability to create and conduct highly disruptive or destructive cyber-attacks, including on critical infrastructure."
        },
        {
          "tier_name": "Offensive cyberoperations",
          "tier_level": 4,
          "capability_threshold": "The model provides a meaningful uplift to a low-skilled actor\u2019s ability to identify and exploit major vulnerabilities or enables a well-resourced and expert actor to develop and execute novel and effective strategies against hardened targets.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Further review and mitigations required."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "Critical: The model provides a meaningful uplift to a low-skilled actor\u2019s ability to identify and exploit major vulnerabilities or enables a well-resourced and expert actor to develop and execute novel and effective strategies against hardened targets."
        },
        {
          "tier_name": "Advanced autonomy",
          "tier_level": 1,
          "capability_threshold": "The model can complete a small number of basic tasks, including software engineering tasks that take a human less than one hour.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Deployment allowed in line with Responsible AI Program requirements."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "Low: The model can complete a small number of basic tasks, including software engineering tasks that take a human less than one hour."
        },
        {
          "tier_name": "Advanced autonomy",
          "tier_level": 2,
          "capability_threshold": "The model can autonomously complete more complex tasks, including software engineering tasks equivalent to a few hours of human labor, but requires human intervention to correct for complex error conditions or changes to the operating environment.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Deployment allowed in line with Responsible AI Program requirements."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "Medium: The model can autonomously complete more complex tasks, including software engineering tasks equivalent to a few hours of human labor."
        },
        {
          "tier_name": "Advanced autonomy",
          "tier_level": 3,
          "capability_threshold": "The model can autonomously complete a range of generalist tasks equivalent to multiple days\u2019 worth of generalist human labor and appropriately correct for complex error conditions, or autonomously complete the vast majority of coding tasks at the level of expert humans.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Further review and mitigations required."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "High: The model can autonomously complete a range of generalist tasks equivalent to multiple days\u2019 worth of generalist human labor."
        },
        {
          "tier_name": "Advanced autonomy",
          "tier_level": 4,
          "capability_threshold": "The model can fully automate the AI R&D pipeline at a fraction of human labor costs, majorly accelerating AI R&D.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Further review and mitigations required."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "Critical: The model can fully automate the AI R&D pipeline at a fraction of human labor costs, majorly accelerating AI R&D."
        }
      ]
    },
    {
      "organization": "xAI",
      "framework_name": "Risk Management Framework",
      "version": "August 20, 2025",
      "risk_tiers": [
        {
          "tier_name": "Basic Refusal Policy",
          "tier_level": 1,
          "capability_threshold": "Models are trained to decline requests showing clear intent to engage in criminal activity which poses risks of severe harm to others.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Public benchmarks like Weapons of Mass Destruction Proxy and Catastrophic Harm Benchmarks"
          ],
          "required_safeguards": [
            "Safety training to recognize and decline harmful requests",
            "System prompts to enforce basic refusal policy",
            "Input and output filters to verify safety"
          ],
          "deployment_restrictions": [
            "Heightened safeguards for requests posing foreseeable and non-trivial risk of large-scale violence or terrorism"
          ],
          "source_quote": "Our most basic safeguard against malicious use is to train and instruct our publicly deployed models to decline requests showing clear intent to engage in criminal activity which poses risks of severe harm to others."
        },
        {
          "tier_name": "Heightened Safeguards",
          "tier_level": 2,
          "capability_threshold": "Models apply heightened safeguards if they receive user prompts that pose a foreseeable and non-trivial risk of resulting in large-scale violence.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Virology Capabilities Test (VCT)",
            "Weapons of Mass Destruction Proxy (WMDP) Benchmark",
            "Biological Lab Protocol Benchmark (BioLP-bench)",
            "Cybench"
          ],
          "required_safeguards": [
            "Redundant layers of safeguards to inhibit user progress in advancing through critical steps",
            "AI-powered filters monitoring user conversations"
          ],
          "deployment_restrictions": [
            "Selective allowance for trusted users to respond to high-risk requests"
          ],
          "source_quote": "xAI aims to reduce the risk that the use of its models might contribute to a bad actor potentially seriously injuring people, property, or national security interests."
        },
        {
          "tier_name": "Advanced Risk Management",
          "tier_level": 3,
          "capability_threshold": "Models must demonstrate robust resistance to adversarial attacks and maintain transparency in operations.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Model Alignment between Statements and Knowledge (MASK)",
            "Sycophancy evaluation"
          ],
          "required_safeguards": [
            "Training to be honest and have values conducive to controllability",
            "Direct instructions to not deceive or mislead users"
          ],
          "deployment_restrictions": [
            "Full functionality may be limited to trusted parties and government agencies"
          ],
          "source_quote": "xAI aims to accurately measure these propensities and reduce them through careful engineering."
        }
      ]
    },
    {
      "organization": "NVIDIA",
      "framework_name": "Frontier AI Risk Assessment",
      "version": "August 2025",
      "risk_tiers": [
        {
          "tier_name": "MR1",
          "tier_level": 1,
          "capability_threshold": "Low risk models with limited capabilities and supervision.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Basic evaluation results documented by engineering teams."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "MR1 - Intended use case: Retail, Entertainment, No intended industry."
        },
        {
          "tier_name": "MR2",
          "tier_level": 2,
          "capability_threshold": "Moderate risk models with some capabilities and supervision.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Evaluation results documented by engineering teams."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "MR2 - Intended use case: Manufacturing, Financial services, Education, Agriculture."
        },
        {
          "tier_name": "MR3",
          "tier_level": 3,
          "capability_threshold": "Higher risk models requiring risk mitigation measures.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Risk mitigation measures and evaluation results documented by engineering teams."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "MR3 - Intended use case: Healthcare, Robotics, Transportation."
        },
        {
          "tier_name": "MR4",
          "tier_level": 4,
          "capability_threshold": "High risk models requiring business unit leader approval.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Detailed risk assessment should be complete and business unit leader approval is required."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "MR4 - Intended use case: Politics, Defense and security."
        },
        {
          "tier_name": "MR5",
          "tier_level": 5,
          "capability_threshold": "Frontier models with undefined capabilities and high levels of autonomy.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "A detailed risk assessment should be complete and approved by an independent committee."
          ],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "MR5 - Intended use case: Wide variety of undefined capabilities."
        }
      ]
    },
    {
      "organization": "Anthropic",
      "framework_name": "Responsible Scaling Policy",
      "version": "1.0",
      "risk_tiers": [
        {
          "tier_name": "ASL-1",
          "tier_level": 1,
          "capability_threshold": "Models which manifestly and obviously pose no risk of catastrophe.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "For example, an LLM from 2018, or an AI system trained only to play chess."
        },
        {
          "tier_name": "ASL-2",
          "tier_level": 2,
          "capability_threshold": "No capabilities likely to cause catastrophe, although early indications of these capabilities.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Evaluate for ASL-3 warning signs when training, using methods and Evaluation Protocol described below."
          ],
          "required_safeguards": [
            "Harden security against opportunistic attackers.",
            "Follow current deployment best practices e.g. model cards, acceptable use policies, misuse escalation procedures, vulnerability reporting, harm refusal techniques, T&S tooling, and partner safety evaluation."
          ],
          "deployment_restrictions": [],
          "source_quote": "For example, an AI system that can provide bioweapon-related information that couldn\u2019t be found via a search engine, but does so too unreliably to be useful in practice."
        },
        {
          "tier_name": "ASL-3",
          "tier_level": 3,
          "capability_threshold": "Low-level autonomous capabilities or access to the model would substantially increase the risk of catastrophic misuse.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Evaluate for ASL-4 warning signs when training, likely similar to but much more involved than the methods described below."
          ],
          "required_safeguards": [
            "Harden security such that non-state attackers are unlikely to be able to steal model weights and advanced threat actors (e.g. states) cannot steal them without significant expense.",
            "Implement internal compartmentalization for training techniques and model hyperparameters.",
            "Implement strong misuse prevention measures, including internal usage controls, automated detection, a vulnerability disclosure process, and maximum jailbreak response times.",
            "Each deployed modality (e.g. API, fine-tuning) must pass intensive expert red-teaming and evaluation measures for catastrophic risks."
          ],
          "deployment_restrictions": [],
          "source_quote": "Access to the model would substantially increase the risk of catastrophic misuse, either by proliferating capabilities, lowering costs, or enabling new methods of attack."
        },
        {
          "tier_name": "ASL-4",
          "tier_level": 4,
          "capability_threshold": "Capabilities and warning sign evaluations defined before training ASL-3 models.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [],
          "required_safeguards": [],
          "deployment_restrictions": [],
          "source_quote": "ASL-4 capabilities and warning sign evaluations defined before training ASL-3 models."
        }
      ]
    },
    {
      "organization": "Google DeepMind",
      "framework_name": "Frontier Safety Framework",
      "version": "1.0",
      "risk_tiers": [
        {
          "tier_name": "Critical Capability Level 1",
          "tier_level": 1,
          "capability_threshold": "Minimal level of capabilities a model must have to play a role in causing severe harm.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Early warning evaluations to detect when a model approaches a CCL."
          ],
          "required_safeguards": [
            "Security measures to prevent exfiltration of models.",
            "Deployment measures to prevent misuse of critical capabilities."
          ],
          "deployment_restrictions": [
            "Mitigations should take into account the overall balance of benefits and risks."
          ],
          "source_quote": "Our initial set of Critical Capability Levels is based on investigation of four domains: autonomy, biosecurity, cybersecurity, and machine learning research and development (R&D)."
        },
        {
          "tier_name": "Critical Capability Level 2",
          "tier_level": 2,
          "capability_threshold": "Higher level of capabilities that could enable severe risks.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Frequent early warning evaluations."
          ],
          "required_safeguards": [
            "Enhanced security measures against model exfiltration.",
            "Stronger deployment restrictions."
          ],
          "deployment_restrictions": [
            "Tighter management of critical capabilities."
          ],
          "source_quote": "Higher level security mitigations result in greater protection against the exfiltration of model weights."
        },
        {
          "tier_name": "Critical Capability Level 3",
          "tier_level": 3,
          "capability_threshold": "Advanced capabilities that pose significant risks.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Comprehensive evaluations to assess risks from critical capabilities."
          ],
          "required_safeguards": [
            "Robust security protocols.",
            "Strict deployment guidelines."
          ],
          "deployment_restrictions": [
            "Potentially limited access to capabilities to prevent misuse."
          ],
          "source_quote": "Striking the optimal balance between mitigating risks and fostering access and innovation is paramount to the responsible development of AI."
        }
      ]
    },
    {
      "organization": "Magic AI, Inc.",
      "framework_name": "AGI Readiness Policy",
      "version": "1.0",
      "risk_tiers": [
        {
          "tier_name": "Dangerous Capability Evaluation Trigger",
          "tier_level": 1,
          "capability_threshold": "Model exceeds a threshold of 50% accuracy on LiveCodeBench.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Public and private coding benchmarks evaluations",
            "Comparison with state-of-the-art models"
          ],
          "required_safeguards": [
            "Implementation of dangerous capability evaluations",
            "Planned mitigations for Covered Threat Models"
          ],
          "deployment_restrictions": [
            "Halt further model development until evaluations are ready"
          ],
          "source_quote": "when, at the end of a training run, our models exceed a threshold of 50% accuracy on LiveCodeBench, we will trigger our commitment to incorporate a full system of dangerous capabilities evaluations and planned mitigations into our AGI Readiness Policy."
        },
        {
          "tier_name": "Critical Capability Threshold",
          "tier_level": 2,
          "capability_threshold": "Model is effective at real-world cyberoffense operations.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Evaluation of model's effectiveness in cyberoffense operations"
          ],
          "required_safeguards": [
            "Adoption of safety measures outlined in the Threat Mitigations section"
          ],
          "deployment_restrictions": [
            "Delay or pause development until dangerous capability detected has been mitigated or contained"
          ],
          "source_quote": "If the engineering team sees evidence that our AI systems have exceeded the current performance thresholds on the public and private benchmarks listed above, the team is responsible for making this known immediately to the leadership team."
        },
        {
          "tier_name": "AI R&D Capability Threshold",
          "tier_level": 3,
          "capability_threshold": "Model facilitates a dramatic acceleration in the rate of effective compute scaling or can effectively replace high-level machine learning researchers.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Evaluation of model's contribution to unsafe proliferation or enhancement of dangerous AI capabilities"
          ],
          "required_safeguards": [
            "Development of detailed dangerous capability evaluations"
          ],
          "deployment_restrictions": [
            "Must have evaluations ready before deployment"
          ],
          "source_quote": "Such capabilities may enable it to contribute to the unsafe proliferation or enhancement of other dangerous AI capabilities."
        },
        {
          "tier_name": "Autonomous Replication and Adaptation Capability Threshold",
          "tier_level": 4,
          "capability_threshold": "Model could autonomously maintain its own operation executing cybercrime and using the proceeds to create arbitrarily many replicas of itself.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Evaluation of model's ability to replicate and execute cybercrime"
          ],
          "required_safeguards": [
            "Implementation of robust security controls"
          ],
          "deployment_restrictions": [
            "Must have adequate evaluations and mitigations before deployment"
          ],
          "source_quote": "If given access to its own weights and prompted to do so, the AI model could autonomously maintain its own operation executing cybercrime."
        },
        {
          "tier_name": "Biological Weapons Assistance Capability Threshold",
          "tier_level": 5,
          "capability_threshold": "Model provides expert-level guidance which increases the accessibility or severity of bioweapon development.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Evaluation of model's guidance in bioweapon development"
          ],
          "required_safeguards": [
            "Development of detailed dangerous capability evaluations"
          ],
          "deployment_restrictions": [
            "Must have evaluations ready before deployment"
          ],
          "source_quote": "With the model\u2019s help, a non-expert malicious actor can synthesize a viable pandemic agent."
        }
      ]
    },
    {
      "organization": "NAVER",
      "framework_name": "AI Safety Framework",
      "version": "1.0",
      "risk_tiers": [
        {
          "tier_name": "Hyper-scale AI",
          "tier_level": 1,
          "capability_threshold": "AI systems with the highest possible capabilities that currently exist or are to come in the next few years.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Periodic reviews or assessments whenever major performance improvements are made."
          ],
          "required_safeguards": [
            "Implement appropriate guardrails around AI technology."
          ],
          "deployment_restrictions": [
            "Delay deploying AI systems until risks are mitigated."
          ],
          "source_quote": "Hyper-scale AI systems"
        },
        {
          "tier_name": "Frontier AI",
          "tier_level": 2,
          "capability_threshold": "AI systems possessing the top capabilities that are available today or will be soon in the near future.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Evaluated quarterly; assessed even before the three-month term if performance increases by 6x."
          ],
          "required_safeguards": [
            "Build guardrails by restricting special-use capabilities."
          ],
          "deployment_restrictions": [
            "Open AI systems only to authorized users to mitigate risks."
          ],
          "source_quote": "Frontier AI possesses the top capabilities that are available today or will be soon in the near future."
        },
        {
          "tier_name": "Future AI",
          "tier_level": 3,
          "capability_threshold": "AI systems that have yet to arrive and can only be evaluated once their capabilities become clearer.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "To be determined later depending on their future capabilities."
          ],
          "required_safeguards": [
            "Implement appropriate guardrails around AI technology."
          ],
          "deployment_restrictions": [
            "Do not deploy AI systems until risks are mitigated."
          ],
          "source_quote": "Future AI refers to AI systems that have yet to arrive and can only be evaluated once their capabilities become clearer."
        }
      ]
    },
    {
      "organization": "Amazon",
      "framework_name": "Amazon\u2019s frontier model safety framework",
      "version": "2025",
      "risk_tiers": [
        {
          "tier_name": "ASL-1",
          "tier_level": 1,
          "capability_threshold": "Basic AI capabilities with minimal risk.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Basic functionality tests"
          ],
          "required_safeguards": [
            "Standard security measures"
          ],
          "deployment_restrictions": [],
          "source_quote": "We will not deploy frontier AI models developed by Amazon that exceed specified risk thresholds without appropriate safeguards in place."
        },
        {
          "tier_name": "ASL-2",
          "tier_level": 2,
          "capability_threshold": "Intermediate AI capabilities with moderate risk.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Intermediate functionality tests",
            "Risk assessment"
          ],
          "required_safeguards": [
            "Enhanced security measures",
            "Monitoring systems"
          ],
          "deployment_restrictions": [
            "Limited to controlled environments"
          ],
          "source_quote": "This Framework focuses on severe risks that are unique to frontier AI models as they scale in size and capability."
        },
        {
          "tier_name": "ASL-3",
          "tier_level": 3,
          "capability_threshold": "Advanced AI capabilities with high risk.",
          "compute_threshold_flops": null,
          "evaluation_requirements": [
            "Comprehensive functionality tests",
            "Extensive risk assessment"
          ],
          "required_safeguards": [
            "Robust security measures",
            "Continuous monitoring"
          ],
          "deployment_restrictions": [
            "Restricted to specific applications"
          ],
          "source_quote": "Our approach to managing these frontier risks complements Amazon's broader approach to responsible AI."
        }
      ]
    }
  ]
}